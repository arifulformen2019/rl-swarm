log_dir: ${oc.env:ROOT,.}/logs

hydra:
  run:
    dir: ${log_dir}
  job_logging:
    handlers:
      console:
        level: INFO
    root:
      level: DEBUG

training:
  max_round: 1000000
  max_stage: 1
  hf_push_frequency: 1
  num_generations: 4
  num_transplant_trees: 2
  seed: 42
  dtype: bfloat16

blockchain:
  alchemy_url: "https://gensyn-testnet.g.alchemy.com/public"
  swarm_contract_address: ${oc.env:SWARM_CONTRACT,null}
  org_id: ${oc.env:ORG_ID,null}
  mainnet_chain_id: 685685
  modal_proxy_url: "http://localhost:3000/api/"
  swarm_coordinator_abi_path: "rgym_exp/contracts/SwarmCoordinator_0.4.2.json"

eval:
  judge_base_url: "https://swarm-judge.internal-apps-central1.clusters.gensyn.ai"

prg_game_config:
  prg_game: ${oc.env:PRG_GAME,null}
  org_id: ${blockchain.org_id}
  modal_proxy_url: ${blockchain.modal_proxy_url}

communications:
  initial_peers:
    - '/ip4/38.101.215.12/tcp/30011/p2p/QmQ2gEXoPJg6iMBSUFWGzAabS2VhnzuS782Y637hGjfsRJ'
    - '/ip4/38.101.215.13/tcp/30012/p2p/QmWhiaLrx3HRZfgXc2i7KW5nMUNK7P9tRc71yFJdGEZKkC'
    - '/ip4/38.101.215.14/tcp/30013/p2p/QmQa1SCfYTxx7RvU7qJJRo79Zm1RAwPpkeLueDVJuBBmFp'
  memory_limits:
    max_memory_mb: 8384  # 2GB max memory per worker
    max_object_size: 167772160  # 50MB max object size
    max_buffer_size: 335544320  # 100MB buffer size
    max_cache_bytes: 671088640
game_manager:
  _target_: rgym_exp.src.manager.SwarmGameManager
  max_stage: ${training.max_stage}
  max_round: ${training.max_round}
  log_dir: ${log_dir}
  hf_token: ${oc.env:HUGGINGFACE_ACCESS_TOKEN,null}
  hf_push_frequency: ${training.hf_push_frequency}
  run_mode: "train_and_evaluate"
  bootnodes: ${communications.initial_peers}
  prg_game_config: ${prg_game_config}
  game_state: 
    _target_: genrl.state.game_state.GameState
    round: 0
    stage: 0
  reward_manager:
    _target_: genrl.rewards.DefaultRewardManager
    reward_fn_store:
      _target_: genrl.rewards.reward_store.RewardFnStore
      max_rounds: ${training.max_round}
      reward_fn_stores:
        - _target_: genrl.rewards.reward_store.RoundRewardFnStore
          num_stages: ${training.max_stage}
          reward_fns:
            - _target_: rgym_exp.src.rewards.RGRewards
  trainer:
    _target_: rgym_exp.src.trainer.GRPOTrainerModule
    models:
      - _target_: transformers.AutoModelForCausalLM.from_pretrained
        pretrained_model_name_or_path: ${oc.env:MODEL_NAME,Qwen/Qwen2.5-3B-Instruct}
        device_map: auto
        torch_dtype: ${training.dtype}
        quantization_config:
          _target_: transformers.BitsAndBytesConfig
          load_in_4bit: true
          bnb_4bit_compute_dtype: ${training.dtype}
          bnb_4bit_use_double_quant: true
          bnb_4bit_quant_type: nf4
    tokenizer:
      _target_: transformers.AutoTokenizer.from_pretrained
      pretrained_model_name_or_path: ${oc.env:MODEL_NAME,Qwen/Qwen2.5-3B-Instruct}
      use_fast: true
    config:
      _target_: genrl.trainer.grpo_trainer.GRPOTrainerConfig
      dtype: ${training.dtype}
      epsilon: 0.2
      epsilon_high: 0.28
      num_generations: ${training.num_generations}
    log_with: wandb
    log_dir: ${log_dir}
    judge_base_url: ${eval.judge_base_url}
  data_manager:
    _target_: rgym_exp.src.data.ReasoningGymDataManager
    yaml_config_path: "rgym_exp/src/datasets.yaml"
    num_train_samples: 4
    num_evaluation_samples: 0
    num_generations: ${training.num_generations}
    system_prompt_id: 'default'
    seed: ${training.seed}
    num_transplant_trees: ${training.num_transplant_trees}
  communication:
    _target_: genrl.communication.hivemind.hivemind_backend.HivemindBackend
    initial_peers: ${communications.initial_peers}
    identity_path: ${oc.env:IDENTITY_PATH,null}
    startup_timeout: 300
    beam_size: 10
    disable_caching: true
    cache_locally: false
    cache_on_store: false
    max_memory_mb: ${communications.memory_limits.max_memory_mb}
    max_object_size: ${communications.memory_limits.max_object_size}
    max_buffer_size: ${communications.memory_limits.max_buffer_size}
  coordinator:
    _target_: rgym_exp.src.coordinator.ModalSwarmCoordinator
    web3_url: ${blockchain.alchemy_url}
    contract_address: ${blockchain.swarm_contract_address}
    org_id: ${blockchain.org_id}
    modal_proxy_url: ${blockchain.modal_proxy_url}
    swarm_coordinator_abi_json: ${blockchain.swarm_coordinator_abi_path}

default_large_model_pool: 
  - unsloth/Phi-4-mini-reasoning-unsloth-bnb-4bit
  - unsloth/Qwen2.5-3B-Instruct-bnb-4bit

default_small_model_pool:
  - Gensyn/Qwen2.5-0.5B-Instruct
  - Qwen/Qwen3-0.6B
